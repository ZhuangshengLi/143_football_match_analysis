# Football Match Analysis

A football match data analysis project based on the European Soccer Database. Transforms raw match and player data into structured datasets for machine learning and visualization.

---

## Data Source

- **European Soccer Database** (Kaggle)  
- Link: https://www.kaggle.com/datasets/hugomathien/soccer  
- Download `database.sqlite` and place it in `inputs/raw/`

---

## Project Structure

```
143_football_match_analysis/
├── main.py                    # Main entry, CLI commands
├── requirements.txt           # Python dependencies
├── inputs/
│   ├── match_features.py      # Match feature engineering (L1/L2/L3)
│   └── raw/
│       └── database.sqlite    # Raw database (download required)
├── outputs/
│   └── clean/
│       └── processed_dataset.npz   # Match feature dataset (generated by process)
├── models/
│   └── ablation.py            # Model A/B/C/D ablation experiments
└── visualization/             # Visualization notebooks
    ├── ECE143_Data_Visualization.ipynb
    └── visualization_DataOverview.ipynb
```

---

## Environment Setup


---

## Usage

```powershell
# Feature engineering
python main.py process
python main.py process -d inputs/raw/database.sqlite -o outputs/clean/processed_dataset.npz

# A/B/C/D ablation
python main.py train
python main.py train --data outputs/clean/processed_dataset.npz
```

```python
from main import DB_PATH, DATA_PATH
from inputs.match_features import build_match_dataset, load_match_dataset

df = build_match_dataset(DB_PATH, DATA_PATH)
df = load_match_dataset(DATA_PATH)
```

---

## Technical Documentation

### 1. Data Processing Pipeline

```
database.sqlite
    │
    └─► build_match_dataset()     # Match feature engineering
            • L1: Player_Attributes aggregation (overall, attack, defense, passing, pace, physical, gk)
            • L2: Team_Attributes tactical style (buildUpPlay, chanceCreation, defence)
            • L3: Match rolling history (win rate, goal diff, Elo, rest days)
            • Strict time alignment: date ≤ match_date
            • Output: processed_dataset.npz
```

### 2. Feature Framework

| Level | Content | Source |
|-------|---------|--------|
| **L1 Static Ability** | overall_mean, attack/defense/passing/pace/physical/gk_index, diff, attack vs defense matching | Player_Attributes |
| **L2 Tactical Style** | buildUpPlaySpeed, chanceCreation*, defencePressure, etc. | Team_Attributes |
| **L3 Dynamic State** | Last 5 win rate, goal diff, home win rate, rest days, Elo | Match rolling history |

**Time alignment**: Player/team attributes use the most recent record with `date ≤ match_date`; L3 rolling/Elo uses only historical matches with `date < match_date` to avoid data leakage.

**Ablation experiments**: Model A (L1) → B (L1+L2) → C (L1+L2+L3) → D (C+odds)

### 3. Output Data Format

| Key | Description |
|-----|-------------|
| X | (N, n_features) Feature matrix |
| y | (N,) Labels. 0=home did not win, 1=home win |
| feature_names | Feature column names |

---

## Design Rationale

### Why This Feature Design?

**L1 Static Ability**: Match outcomes are directly related to individual player ability. Aggregating Player_Attributes by attack, defense, passing, pace, physical, and goalkeeper dimensions captures squad strength comparison. Cross terms like `diff`, `attack_home_vs_defense_away`, and `gk_home_vs_shooting_away` reflect attack-defense matching, consistent with football intuition.

**L2 Tactical Style**: Team_Attributes provide tactical preferences (possession tempo, chance creation, defensive pressure, etc.). Different styles have counter relationships; player ability alone cannot capture tactical dynamics.

**L3 Dynamic State**: Recent form, Elo, and rest days reflect current team state and fitness. Rolling features capture short-term factors like winning/losing streaks and fatigue, compensating for the lag of static attributes.

**Odds (B365)**: Betting odds aggregate substantial market information and are among the strongest single predictors. Model D includes odds to evaluate the gap between "pure features" and "features + market information".

### Why Logistic Regression?

1. **Interpretability**: Coefficients quantify each feature's contribution to home win probability, facilitating analysis and reporting.
2. **Limited sample size**: European Soccer Database has roughly thousands of valid matches; linear models have fewer parameters and resist overfitting.
3. **Structured tabular data**: Features are hand-crafted; linear relationships suffice for most home-away strength comparisons.
4. **Training stability**: No hyperparameter tuning needed, fast convergence, suitable for rapid ablation iteration.

### Why Do Neural Networks Perform Similarly or Worse Than Logistic Regression?

In football match prediction, MLPs, LSTMs, and other neural networks often match or underperform logistic regression in AUC. Main reasons:

| Factor | Description |
|--------|-------------|
| **Insufficient data scale** | ~Thousands of valid samples; neural networks have many parameters and overfit easily. Logistic regression has O(n_features) parameters and generalizes more stably. |
| **Tabular data nature** | Features are hand-crafted structured numerics with limited nonlinear interactions. Logistic regression fits well; neural network advantages on tabular data typically require millions of samples. |
| **Inherent task noise** | Football outcomes are affected by injuries, refereeing, random events, etc., with irreducible error. Adding model complexity cannot remove noise and tends to fit it instead. |
| **Overfitting risk** | Neural networks easily achieve higher AUC on training data but generalize poorly on test. Logistic regression is more consistent across train/test. |
| **Regularization cost** | Heavy regularization and early stopping are needed to curb overfitting; results often approach linear models while compute and tuning cost are higher. |

**Conclusion**: For small-to-medium scale, tabular, high-noise football prediction, logistic regression is the safer choice; neural networks struggle to show advantages in such settings.

---

## API Reference

### `inputs.match_features`

| Function | Signature | Description |
|----------|------------|-------------|
| `build_match_dataset` | `(database_path, output_path) -> df` | Build L1/L2/L3 features and save |
| `load_match_dataset` | `(path) -> df` | Load match dataset (.npz or .parquet) |
| `get_feature_groups` | `(df) -> dict` | Return ablation experiment variable groups |

### `models.ablation`

| Function | Signature | Description |
|----------|------------|-------------|
| `run_ablation` | `(df, feature_groups?, ...) -> DataFrame` | Run Model A/B/C/D ablation experiments |

### `main.py` Path Constants

| Constant | Description |
|----------|-------------|
| `ROOT` | Project root directory |
| `DB_PATH` | Default database path |
| `DATA_PATH` | Default data output path |
